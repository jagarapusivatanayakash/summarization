{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install transformers\n","!pip install rouge"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T18:04:39.533116Z","iopub.status.busy":"2023-09-01T18:04:39.532286Z","iopub.status.idle":"2023-09-01T18:04:57.212655Z","shell.execute_reply":"2023-09-01T18:04:57.211478Z","shell.execute_reply.started":"2023-09-01T18:04:39.533077Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting rouge.score\n","  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.2.4)\n","Collecting py7zr\n","  Downloading py7zr-0.20.6-py3-none-any.whl (66 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.7/66.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge.score) (1.4.0)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge.score) (1.23.5)\n","Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge.score) (1.16.0)\n","Requirement already satisfied: texttable in /opt/conda/lib/python3.10/site-packages (from py7zr) (1.6.7)\n","Collecting pycryptodomex>=3.6.6 (from py7zr)\n","  Downloading pycryptodomex-3.18.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hCollecting pyzstd>=0.14.4 (from py7zr)\n","  Downloading pyzstd-0.15.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (412 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.3/412.3 kB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pyppmd<1.1.0,>=0.18.1 (from py7zr)\n","  Downloading pyppmd-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.8/138.8 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pybcj>=0.6.0 (from py7zr)\n","  Downloading pybcj-1.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.8/49.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multivolumefile>=0.2.3 (from py7zr)\n","  Downloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n","Collecting brotli>=1.0.9 (from py7zr)\n","  Downloading Brotli-1.0.9-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n","\u001b[?25hCollecting inflate64>=0.3.1 (from py7zr)\n","  Downloading inflate64-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from py7zr) (5.9.3)\n","Building wheels for collected packages: rouge.score\n","  Building wheel for rouge.score (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for rouge.score: filename=rouge_score-0.1.2-py3-none-any.whl size=24954 sha256=6aed7f4c87e88e1c82ddd15154438620a74531a269765478d63665f92cfcd296\n","  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n","Successfully built rouge.score\n","Installing collected packages: brotli, pyzstd, pyppmd, pycryptodomex, pybcj, multivolumefile, inflate64, rouge.score, py7zr\n","Successfully installed brotli-1.0.9 inflate64-0.3.1 multivolumefile-0.2.3 py7zr-0.20.6 pybcj-1.0.1 pycryptodomex-3.18.0 pyppmd-1.0.0 pyzstd-0.15.9 rouge.score-0.1.2\n"]}],"source":["!pip install rouge.score nltk py7zr"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T18:04:57.214885Z","iopub.status.busy":"2023-09-01T18:04:57.214506Z","iopub.status.idle":"2023-09-01T18:05:09.393090Z","shell.execute_reply":"2023-09-01T18:05:09.391772Z","shell.execute_reply.started":"2023-09-01T18:04:57.214856Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.30.2)\n","Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.16.4)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.3.1)\n","Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.65.0)\n","Requirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (11.0.0)\n","Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.6)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (1.5.3)\n","Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.2.0)\n","Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.14)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.8.4)\n","Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.18.0)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (3.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.5.7)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"]}],"source":["!pip install transformers datasets "]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T18:14:10.907113Z","iopub.status.busy":"2023-09-01T18:14:10.906738Z","iopub.status.idle":"2023-09-01T18:14:27.603054Z","shell.execute_reply":"2023-09-01T18:14:27.601977Z","shell.execute_reply.started":"2023-09-01T18:14:10.907081Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n","caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n","  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n","/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n","caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n","  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"]}],"source":["import datasets\n","import transformers\n","import pandas as pd\n","from datasets import Dataset\n","\n","#Tokenizer\n","from transformers import RobertaTokenizerFast\n","\n","#Encoder-Decoder Model\n","from transformers import EncoderDecoderModel,Seq2SeqTrainingArguments\n","\n","#Training\n","# import seq2seq\n","from transformers import Seq2SeqTrainer\n","#from seq2seq_trainer import Seq2SeqTrainer\n","from transformers import TrainingArguments\n","from dataclasses import dataclass, field\n","from typing import Optional\n","from transformers import AutoConfig, AutoModelForSequenceClassification, AutoTokenizer, EvalPrediction, GlueDataset\n","from transformers import GlueDataTrainingArguments as DataTrainingArguments\n","from transformers import (\n","    HfArgumentParser,\n","    Trainer,\n","    TrainingArguments,\n","    glue_compute_metrics,\n","    glue_output_modes,\n","    glue_tasks_num_labels,\n","    set_seed,\n",")"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T14:25:26.865495Z","iopub.status.busy":"2023-09-01T14:25:26.865140Z","iopub.status.idle":"2023-09-01T14:25:26.869734Z","shell.execute_reply":"2023-09-01T14:25:26.868642Z","shell.execute_reply.started":"2023-09-01T14:25:26.865459Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T14:25:26.871795Z","iopub.status.busy":"2023-09-01T14:25:26.871198Z","iopub.status.idle":"2023-09-01T14:25:54.230434Z","shell.execute_reply":"2023-09-01T14:25:54.229433Z","shell.execute_reply.started":"2023-09-01T14:25:26.871760Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Data size: 287113\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>article</th>\n","      <th>highlights</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>By . Associated Press . PUBLISHED: . 14:11 EST...</td>\n","      <td>Bishop John Folda, of North Dakota, is taking ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>(CNN) -- Ralph Mata was an internal affairs li...</td>\n","      <td>Criminal complaint: Cop used his role to help ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>A drunk driver who killed a young woman in a h...</td>\n","      <td>Craig Eccleston-Todd, 27, had drunk at least t...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>(CNN) -- With a breezy sweep of his pen Presid...</td>\n","      <td>Nina dos Santos says Europe must be ready to a...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Fleetwood are the only team still to have a 10...</td>\n","      <td>Fleetwood top of League One after 2-0 win at S...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>287108</th>\n","      <td>By . James Rush . Former first daughter Chelse...</td>\n","      <td>Chelsea Clinton said question of running for o...</td>\n","    </tr>\n","    <tr>\n","      <th>287109</th>\n","      <td>An apologetic Vanilla Ice has given his first ...</td>\n","      <td>Vanilla Ice, 47 - real name Robert Van Winkle ...</td>\n","    </tr>\n","    <tr>\n","      <th>287110</th>\n","      <td>America's most lethal sniper claimed he wished...</td>\n","      <td>America's most lethal sniper made comment in i...</td>\n","    </tr>\n","    <tr>\n","      <th>287111</th>\n","      <td>By . Sara Malm . PUBLISHED: . 12:19 EST, 8 Mar...</td>\n","      <td>A swarm of more than one million has crossed b...</td>\n","    </tr>\n","    <tr>\n","      <th>287112</th>\n","      <td>(CNN)Former Florida Gov. Jeb Bush has decided ...</td>\n","      <td>Other 2016 hopefuls maintain that Bush's annou...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>287113 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                  article  \\\n","0       By . Associated Press . PUBLISHED: . 14:11 EST...   \n","1       (CNN) -- Ralph Mata was an internal affairs li...   \n","2       A drunk driver who killed a young woman in a h...   \n","3       (CNN) -- With a breezy sweep of his pen Presid...   \n","4       Fleetwood are the only team still to have a 10...   \n","...                                                   ...   \n","287108  By . James Rush . Former first daughter Chelse...   \n","287109  An apologetic Vanilla Ice has given his first ...   \n","287110  America's most lethal sniper claimed he wished...   \n","287111  By . Sara Malm . PUBLISHED: . 12:19 EST, 8 Mar...   \n","287112  (CNN)Former Florida Gov. Jeb Bush has decided ...   \n","\n","                                               highlights  \n","0       Bishop John Folda, of North Dakota, is taking ...  \n","1       Criminal complaint: Cop used his role to help ...  \n","2       Craig Eccleston-Todd, 27, had drunk at least t...  \n","3       Nina dos Santos says Europe must be ready to a...  \n","4       Fleetwood top of League One after 2-0 win at S...  \n","...                                                   ...  \n","287108  Chelsea Clinton said question of running for o...  \n","287109  Vanilla Ice, 47 - real name Robert Van Winkle ...  \n","287110  America's most lethal sniper made comment in i...  \n","287111  A swarm of more than one million has crossed b...  \n","287112  Other 2016 hopefuls maintain that Bush's annou...  \n","\n","[287113 rows x 2 columns]"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","df1=pd.read_csv(r\"/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/train.csv\")\n","df1.drop(columns=['id'],inplace=True)\n","df1 = df1.dropna()\n","print(\"Data size:\",len(df1))\n","df1.head()\n","df1"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T14:25:54.232668Z","iopub.status.busy":"2023-09-01T14:25:54.231969Z","iopub.status.idle":"2023-09-01T14:25:55.504652Z","shell.execute_reply":"2023-09-01T14:25:55.503553Z","shell.execute_reply.started":"2023-09-01T14:25:54.232628Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Data size: 13368\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>article</th>\n","      <th>highlights</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Sally Forrest, an actress-dancer who graced th...</td>\n","      <td>Sally Forrest, an actress-dancer who graced th...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>A middle-school teacher in China has inked hun...</td>\n","      <td>Works include pictures of Presidential Palace ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>A man convicted of killing the father and sist...</td>\n","      <td>Iftekhar Murtaza, 29, was convicted a year ago...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Avid rugby fan Prince Harry could barely watch...</td>\n","      <td>Prince Harry in attendance for England's crunc...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>A Triple M Radio producer has been inundated w...</td>\n","      <td>Nick Slater's colleagues uploaded a picture to...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>13363</th>\n","      <td>All shops will be allowed to offer ‘click and ...</td>\n","      <td>Shops won't have to apply for planning permiss...</td>\n","    </tr>\n","    <tr>\n","      <th>13364</th>\n","      <td>Mo Farah has had his nationality called into q...</td>\n","      <td>Mo Farah broke the European half-marathon reco...</td>\n","    </tr>\n","    <tr>\n","      <th>13365</th>\n","      <td>Wolves kept their promotion hopes alive with a...</td>\n","      <td>Wolves are three points off the play-off place...</td>\n","    </tr>\n","    <tr>\n","      <th>13366</th>\n","      <td>A Brown University graduate student  has died ...</td>\n","      <td>Hyoun Ju Sohn, a 25-year-old doctoral student,...</td>\n","    </tr>\n","    <tr>\n","      <th>13367</th>\n","      <td>As thousands of young Australians look to buy ...</td>\n","      <td>60% of estate agents believe owning a home is ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>13368 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                 article  \\\n","0      Sally Forrest, an actress-dancer who graced th...   \n","1      A middle-school teacher in China has inked hun...   \n","2      A man convicted of killing the father and sist...   \n","3      Avid rugby fan Prince Harry could barely watch...   \n","4      A Triple M Radio producer has been inundated w...   \n","...                                                  ...   \n","13363  All shops will be allowed to offer ‘click and ...   \n","13364  Mo Farah has had his nationality called into q...   \n","13365  Wolves kept their promotion hopes alive with a...   \n","13366  A Brown University graduate student  has died ...   \n","13367  As thousands of young Australians look to buy ...   \n","\n","                                              highlights  \n","0      Sally Forrest, an actress-dancer who graced th...  \n","1      Works include pictures of Presidential Palace ...  \n","2      Iftekhar Murtaza, 29, was convicted a year ago...  \n","3      Prince Harry in attendance for England's crunc...  \n","4      Nick Slater's colleagues uploaded a picture to...  \n","...                                                  ...  \n","13363  Shops won't have to apply for planning permiss...  \n","13364  Mo Farah broke the European half-marathon reco...  \n","13365  Wolves are three points off the play-off place...  \n","13366  Hyoun Ju Sohn, a 25-year-old doctoral student,...  \n","13367  60% of estate agents believe owning a home is ...  \n","\n","[13368 rows x 2 columns]"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["df2=pd.read_csv(r\"/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/validation.csv\")\n","df2.drop(columns=['id'],inplace=True)\n","df2 = df2.dropna()\n","print(\"Data size:\",len(df2))\n","df2.head()\n","df2"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T14:25:55.506609Z","iopub.status.busy":"2023-09-01T14:25:55.506147Z","iopub.status.idle":"2023-09-01T14:26:00.263368Z","shell.execute_reply":"2023-09-01T14:26:00.262370Z","shell.execute_reply.started":"2023-09-01T14:25:55.506573Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(                                                  article  \\\n"," 0       By . Associated Press . PUBLISHED: . 14:11 EST...   \n"," 1       (CNN) -- Ralph Mata was an internal affairs li...   \n"," 2       A drunk driver who killed a young woman in a h...   \n"," 3       (CNN) -- With a breezy sweep of his pen Presid...   \n"," 4       Fleetwood are the only team still to have a 10...   \n"," ...                                                   ...   \n"," 287108  By . James Rush . Former first daughter Chelse...   \n"," 287109  An apologetic Vanilla Ice has given his first ...   \n"," 287110  America's most lethal sniper claimed he wished...   \n"," 287111  By . Sara Malm . PUBLISHED: . 12:19 EST, 8 Mar...   \n"," 287112  (CNN)Former Florida Gov. Jeb Bush has decided ...   \n"," \n","                                                highlights  \n"," 0       Bishop John Folda, of North Dakota, is taking ...  \n"," 1       Criminal complaint: Cop used his role to help ...  \n"," 2       Craig Eccleston-Todd, 27, had drunk at least t...  \n"," 3       Nina dos Santos says Europe must be ready to a...  \n"," 4       Fleetwood top of League One after 2-0 win at S...  \n"," ...                                                   ...  \n"," 287108  Chelsea Clinton said question of running for o...  \n"," 287109  Vanilla Ice, 47 - real name Robert Van Winkle ...  \n"," 287110  America's most lethal sniper made comment in i...  \n"," 287111  A swarm of more than one million has crossed b...  \n"," 287112  Other 2016 hopefuls maintain that Bush's annou...  \n"," \n"," [287113 rows x 2 columns],\n","                                                  article  \\\n"," 0      Sally Forrest, an actress-dancer who graced th...   \n"," 1      A middle-school teacher in China has inked hun...   \n"," 2      A man convicted of killing the father and sist...   \n"," 3      Avid rugby fan Prince Harry could barely watch...   \n"," 4      A Triple M Radio producer has been inundated w...   \n"," ...                                                  ...   \n"," 13363  All shops will be allowed to offer ‘click and ...   \n"," 13364  Mo Farah has had his nationality called into q...   \n"," 13365  Wolves kept their promotion hopes alive with a...   \n"," 13366  A Brown University graduate student  has died ...   \n"," 13367  As thousands of young Australians look to buy ...   \n"," \n","                                               highlights  \n"," 0      Sally Forrest, an actress-dancer who graced th...  \n"," 1      Works include pictures of Presidential Palace ...  \n"," 2      Iftekhar Murtaza, 29, was convicted a year ago...  \n"," 3      Prince Harry in attendance for England's crunc...  \n"," 4      Nick Slater's colleagues uploaded a picture to...  \n"," ...                                                  ...  \n"," 13363  Shops won't have to apply for planning permiss...  \n"," 13364  Mo Farah broke the European half-marathon reco...  \n"," 13365  Wolves are three points off the play-off place...  \n"," 13366  Hyoun Ju Sohn, a 25-year-old doctoral student,...  \n"," 13367  60% of estate agents believe owning a home is ...  \n"," \n"," [13368 rows x 2 columns])"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["from datasets import Dataset\n","train_data=Dataset.from_pandas(df1[:287113])\n","val_data=Dataset.from_pandas(df2[:13368])\n","df1,df2"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T14:26:00.265907Z","iopub.status.busy":"2023-09-01T14:26:00.265142Z","iopub.status.idle":"2023-09-01T14:26:00.271300Z","shell.execute_reply":"2023-09-01T14:26:00.270221Z","shell.execute_reply.started":"2023-09-01T14:26:00.265867Z"},"trusted":true},"outputs":[],"source":["del df1,df2"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T14:26:00.277606Z","iopub.status.busy":"2023-09-01T14:26:00.276597Z","iopub.status.idle":"2023-09-01T14:40:47.198948Z","shell.execute_reply":"2023-09-01T14:40:47.198001Z","shell.execute_reply.started":"2023-09-01T14:26:00.277565Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b764ff791c604ecf948c9da907dd018d","version_major":2,"version_minor":0},"text/plain":["Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8677c188987f473f987f7b765446c413","version_major":2,"version_minor":0},"text/plain":["Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bc6f121b80054dd0affdd8de8babee2e","version_major":2,"version_minor":0},"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3e83fcf083ba4407acd5ecb7f57127b1","version_major":2,"version_minor":0},"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b1e6e29d329b43eda277510202414348","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/17945 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1c755255c876424bbfebaa00b486f537","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/836 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"}],"source":["tokenizer = RobertaTokenizerFast.from_pretrained(\"roberta-base\")\n","tokenizer.bos_token = tokenizer.cls_token\n","tokenizer.eos_token = tokenizer.sep_token\n","#parameter setting\n","batch_size=16 #\n","encoder_max_length=512\n","decoder_max_length=128\n","\n","def process_data_to_model_inputs(batch):\n","    inputs = tokenizer(batch[\"article\"], padding=\"max_length\", truncation=True, max_length=encoder_max_length)\n","    outputs = tokenizer(batch[\"highlights\"], padding=\"max_length\", truncation=True, max_length=decoder_max_length)\n","\n","    batch[\"input_ids\"] = inputs.input_ids\n","    batch[\"attention_mask\"] = inputs.attention_mask\n","    batch[\"decoder_input_ids\"] = outputs.input_ids\n","    batch[\"decoder_attention_mask\"] = outputs.attention_mask\n","    batch[\"labels\"] = outputs.input_ids.copy()\n","    batch[\"labels\"] = [[-100 if token == tokenizer.pad_token_id else token for token in labels] for labels in batch[\"labels\"]]\n","\n","    return batch\n","\n","#processing training data\n","train_data = train_data.map(\n","    process_data_to_model_inputs, \n","    batched=True, \n","    batch_size=batch_size, \n","    remove_columns=[\"article\", \"highlights\"]\n",")\n","train_data.set_format(\n","    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"decoder_input_ids\", \"decoder_attention_mask\", \"labels\"],\n",")\n","\n","#processing validation data\n","val_data = val_data.map(\n","    process_data_to_model_inputs, \n","    batched=True, \n","    batch_size=batch_size, \n","    remove_columns=[\"article\", \"highlights\"]\n",")\n","val_data.set_format(\n","    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"decoder_input_ids\", \"decoder_attention_mask\", \"labels\"],\n",")"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T14:40:47.200981Z","iopub.status.busy":"2023-09-01T14:40:47.200410Z","iopub.status.idle":"2023-09-01T14:40:53.269517Z","shell.execute_reply":"2023-09-01T14:40:53.268462Z","shell.execute_reply.started":"2023-09-01T14:40:47.200945Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d8c325d907ac4abeafeaa1096817d39f","version_major":2,"version_minor":0},"text/plain":["Downloading model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of RobertaForCausalLM were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.encoder.layer.8.crossattention.self.key.bias', 'roberta.encoder.layer.7.crossattention.self.query.weight', 'roberta.encoder.layer.3.crossattention.self.value.weight', 'roberta.encoder.layer.9.crossattention.self.value.weight', 'roberta.encoder.layer.10.crossattention.self.value.weight', 'roberta.encoder.layer.11.crossattention.self.query.weight', 'roberta.encoder.layer.8.crossattention.self.key.weight', 'roberta.encoder.layer.7.crossattention.self.key.weight', 'roberta.encoder.layer.0.crossattention.self.query.bias', 'roberta.encoder.layer.2.crossattention.self.value.bias', 'roberta.encoder.layer.8.crossattention.self.value.bias', 'roberta.encoder.layer.0.crossattention.self.key.bias', 'roberta.encoder.layer.3.crossattention.self.key.weight', 'roberta.encoder.layer.8.crossattention.output.dense.bias', 'roberta.encoder.layer.5.crossattention.self.key.bias', 'roberta.encoder.layer.2.crossattention.output.dense.bias', 'roberta.encoder.layer.0.crossattention.output.dense.weight', 'roberta.encoder.layer.6.crossattention.output.dense.weight', 'roberta.encoder.layer.5.crossattention.self.value.bias', 'roberta.encoder.layer.9.crossattention.self.query.bias', 'roberta.encoder.layer.3.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.4.crossattention.self.key.weight', 'roberta.encoder.layer.6.crossattention.output.dense.bias', 'roberta.encoder.layer.0.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.8.crossattention.self.query.weight', 'roberta.encoder.layer.11.crossattention.self.value.bias', 'roberta.encoder.layer.11.crossattention.self.value.weight', 'roberta.encoder.layer.1.crossattention.self.value.bias', 'roberta.encoder.layer.5.crossattention.output.dense.weight', 'roberta.encoder.layer.8.crossattention.self.value.weight', 'roberta.encoder.layer.7.crossattention.output.dense.weight', 'roberta.encoder.layer.9.crossattention.self.value.bias', 'roberta.encoder.layer.6.crossattention.self.key.bias', 'roberta.encoder.layer.10.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.9.crossattention.self.key.bias', 'roberta.encoder.layer.2.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.9.crossattention.output.dense.bias', 'roberta.encoder.layer.7.crossattention.self.query.bias', 'roberta.encoder.layer.8.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.3.crossattention.output.dense.weight', 'roberta.encoder.layer.11.crossattention.self.query.bias', 'roberta.encoder.layer.3.crossattention.output.dense.bias', 'roberta.encoder.layer.9.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.2.crossattention.self.key.weight', 'roberta.encoder.layer.10.crossattention.self.value.bias', 'roberta.encoder.layer.6.crossattention.self.key.weight', 'roberta.encoder.layer.4.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.8.crossattention.self.query.bias', 'roberta.encoder.layer.3.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.1.crossattention.self.key.bias', 'roberta.encoder.layer.5.crossattention.self.key.weight', 'roberta.encoder.layer.11.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.9.crossattention.self.key.weight', 'roberta.encoder.layer.1.crossattention.self.query.bias', 'roberta.encoder.layer.1.crossattention.self.value.weight', 'roberta.encoder.layer.2.crossattention.self.query.weight', 'roberta.encoder.layer.1.crossattention.self.key.weight', 'roberta.encoder.layer.10.crossattention.self.key.bias', 'roberta.encoder.layer.4.crossattention.self.query.weight', 'roberta.encoder.layer.1.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.4.crossattention.self.value.bias', 'roberta.encoder.layer.10.crossattention.self.key.weight', 'roberta.encoder.layer.9.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.2.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.7.crossattention.output.dense.bias', 'roberta.encoder.layer.0.crossattention.self.query.weight', 'roberta.encoder.layer.5.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.5.crossattention.self.query.weight', 'roberta.encoder.layer.4.crossattention.self.value.weight', 'roberta.encoder.layer.0.crossattention.self.value.bias', 'roberta.encoder.layer.9.crossattention.output.dense.weight', 'roberta.encoder.layer.10.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.1.crossattention.output.dense.bias', 'roberta.encoder.layer.7.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.3.crossattention.self.query.bias', 'roberta.encoder.layer.5.crossattention.output.dense.bias', 'roberta.encoder.layer.7.crossattention.self.value.weight', 'roberta.encoder.layer.10.crossattention.output.dense.weight', 'roberta.encoder.layer.6.crossattention.self.value.bias', 'roberta.encoder.layer.0.crossattention.self.value.weight', 'roberta.encoder.layer.4.crossattention.output.dense.weight', 'roberta.encoder.layer.10.crossattention.self.query.bias', 'roberta.encoder.layer.1.crossattention.output.dense.weight', 'roberta.encoder.layer.6.crossattention.self.query.bias', 'roberta.encoder.layer.3.crossattention.self.value.bias', 'roberta.encoder.layer.1.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.5.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.6.crossattention.self.query.weight', 'roberta.encoder.layer.0.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.5.crossattention.self.query.bias', 'roberta.encoder.layer.7.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.7.crossattention.self.key.bias', 'roberta.encoder.layer.11.crossattention.output.dense.weight', 'roberta.encoder.layer.6.crossattention.self.value.weight', 'roberta.encoder.layer.0.crossattention.output.dense.bias', 'roberta.encoder.layer.0.crossattention.self.key.weight', 'roberta.encoder.layer.4.crossattention.self.query.bias', 'roberta.encoder.layer.7.crossattention.self.value.bias', 'roberta.encoder.layer.11.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.4.crossattention.output.dense.bias', 'roberta.encoder.layer.11.crossattention.self.key.weight', 'roberta.encoder.layer.8.crossattention.output.dense.weight', 'roberta.encoder.layer.10.crossattention.output.dense.bias', 'roberta.encoder.layer.8.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.2.crossattention.self.query.bias', 'roberta.encoder.layer.2.crossattention.self.value.weight', 'roberta.encoder.layer.11.crossattention.self.key.bias', 'roberta.encoder.layer.4.crossattention.self.key.bias', 'roberta.encoder.layer.10.crossattention.self.query.weight', 'roberta.encoder.layer.4.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.2.crossattention.output.dense.weight', 'roberta.encoder.layer.3.crossattention.self.key.bias', 'roberta.encoder.layer.3.crossattention.self.query.weight', 'roberta.encoder.layer.1.crossattention.self.query.weight', 'roberta.encoder.layer.9.crossattention.self.query.weight', 'roberta.encoder.layer.2.crossattention.self.key.bias', 'roberta.encoder.layer.11.crossattention.output.dense.bias', 'roberta.encoder.layer.5.crossattention.self.value.weight', 'roberta.encoder.layer.6.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.6.crossattention.output.LayerNorm.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The following encoder weights were not tied to the decoder ['roberta/pooler']\n"]}],"source":["\n","from transformers import EncoderDecoderModel\n","\n","roberta_shared = EncoderDecoderModel.from_encoder_decoder_pretrained(\"roberta-base\", \"roberta-base\", tie_encoder_decoder=True)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T14:40:53.271324Z","iopub.status.busy":"2023-09-01T14:40:53.270987Z","iopub.status.idle":"2023-09-01T14:40:53.276954Z","shell.execute_reply":"2023-09-01T14:40:53.275934Z","shell.execute_reply.started":"2023-09-01T14:40:53.271297Z"},"trusted":true},"outputs":[],"source":["roberta_shared.config.decoder_start_token_id = tokenizer.bos_token_id                                             \n","roberta_shared.config.eos_token_id = tokenizer.eos_token_id\n","\n","# sensible parameters for beam search\n","# set decoding params                               \n","roberta_shared.config.max_length = 142\n","roberta_shared.config.early_stopping = True\n","roberta_shared.config.no_repeat_ngram_size = 3\n","roberta_shared.config.length_penalty = 2.0\n","roberta_shared.config.num_beams = 4\n","roberta_shared.config.vocab_size = roberta_shared.config.encoder.vocab_size"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T14:40:53.278958Z","iopub.status.busy":"2023-09-01T14:40:53.278375Z","iopub.status.idle":"2023-09-01T14:41:05.473273Z","shell.execute_reply":"2023-09-01T14:41:05.471960Z","shell.execute_reply.started":"2023-09-01T14:40:53.278921Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","Requirement already satisfied: rouge_score in /opt/conda/lib/python3.10/site-packages (0.1.2)\n","Requirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.4.0)\n","Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score) (3.2.4)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.23.5)\n","Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install rouge_score"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T14:41:05.475812Z","iopub.status.busy":"2023-09-01T14:41:05.475418Z","iopub.status.idle":"2023-09-01T14:41:05.483327Z","shell.execute_reply":"2023-09-01T14:41:05.482366Z","shell.execute_reply.started":"2023-09-01T14:41:05.475773Z"},"trusted":true},"outputs":[],"source":["from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T14:41:05.485354Z","iopub.status.busy":"2023-09-01T14:41:05.484863Z","iopub.status.idle":"2023-09-01T14:41:06.573878Z","shell.execute_reply":"2023-09-01T14:41:06.572854Z","shell.execute_reply.started":"2023-09-01T14:41:05.485321Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"29b23496a0b04fe18b193cc93ba22d81","version_major":2,"version_minor":0},"text/plain":["Downloading builder script:   0%|          | 0.00/2.16k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["rouge = datasets.load_metric(\"rouge\")\n","\n","def compute_metrics(pred):\n","    labels_ids = pred.label_ids\n","    pred_ids = pred.predictions\n","\n","    # all unnecessary tokens are removed\n","    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n","    labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n","    label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n","\n","    rouge_output = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rouge2\"])[\"rouge2\"].mid\n","\n","    return {\n","        \"rouge2_precision\": round(rouge_output.precision, 4),\n","        \"rouge2_recall\": round(rouge_output.recall, 4),\n","        \"rouge2_fmeasure\": round(rouge_output.fmeasure, 4),\n","    }"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T14:41:06.576474Z","iopub.status.busy":"2023-09-01T14:41:06.575758Z","iopub.status.idle":"2023-09-01T14:42:11.052146Z","shell.execute_reply":"2023-09-01T14:42:11.050897Z","shell.execute_reply.started":"2023-09-01T14:41:06.576437Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","Cloning into 'seq2seq'...\n","remote: Enumerating objects: 5995, done.\u001b[K\n","remote: Total 5995 (delta 0), reused 0 (delta 0), pack-reused 5995\u001b[K\n","Receiving objects: 100% (5995/5995), 1.63 MiB | 8.45 MiB/s, done.\n","Resolving deltas: 100% (4189/4189), done.\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","Obtaining file:///kaggle/working/seq2seq\n","  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from seq2seq==0.1) (1.23.5)\n","Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from seq2seq==0.1) (3.7.1)\n","Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from seq2seq==0.1) (6.0)\n","Collecting pyrouge (from seq2seq==0.1)\n","  Downloading pyrouge-0.1.3.tar.gz (60 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.5/60.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->seq2seq==0.1) (1.1.0)\n","Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->seq2seq==0.1) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->seq2seq==0.1) (4.40.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->seq2seq==0.1) (1.4.4)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->seq2seq==0.1) (21.3)\n","Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->seq2seq==0.1) (9.5.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->seq2seq==0.1) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->seq2seq==0.1) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->seq2seq==0.1) (1.16.0)\n","Building wheels for collected packages: pyrouge\n","  Building wheel for pyrouge (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for pyrouge: filename=pyrouge-0.1.3-py3-none-any.whl size=191622 sha256=300c88f024f98b12027886aab2865b37a7d3c15c87eb3f02e17e2bcbc23234a6\n","  Stored in directory: /root/.cache/pip/wheels/9a/67/12/c5dd8ef8b4152bb8789eafd2a74a734e2dc7bb9eae02b768e7\n","Successfully built pyrouge\n","Installing collected packages: pyrouge, seq2seq\n","  Running setup.py develop for seq2seq\n","Successfully installed pyrouge-0.1.3 seq2seq-0.1\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","Collecting git+https://github.com/huggingface/transformers\n","  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-eng1emgz\n","  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-eng1emgz\n","  Resolved https://github.com/huggingface/transformers to commit 69c5b8f1861bf449339cbcdcd0d0e4a98e9a4c6b\n","  Installing build dependencies ... \u001b[?25ldone\n","\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n","\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0.dev0) (3.12.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0.dev0) (0.16.4)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0.dev0) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0.dev0) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0.dev0) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0.dev0) (2023.6.3)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0.dev0) (2.31.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0.dev0) (0.13.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0.dev0) (0.3.1)\n","Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0.dev0) (4.65.0)\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers==4.33.0.dev0) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers==4.33.0.dev0) (4.6.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.33.0.dev0) (3.0.9)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.33.0.dev0) (3.1.0)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.33.0.dev0) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.33.0.dev0) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.33.0.dev0) (2023.5.7)\n","Building wheels for collected packages: transformers\n","  Building wheel for transformers (pyproject.toml) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for transformers: filename=transformers-4.33.0.dev0-py3-none-any.whl size=7634073 sha256=1393720ee4275391b53f213fdc242c8a6f7c6495e777bfd0813647e4feadd013\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-_he2kxib/wheels/c0/14/d6/6c9a5582d2ac191ec0a483be151a4495fe1eb2a6706ca49f1b\n","Successfully built transformers\n","Installing collected packages: transformers\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.30.2\n","    Uninstalling transformers-4.30.2:\n","      Successfully uninstalled transformers-4.30.2\n","Successfully installed transformers-4.33.0.dev0\n"]}],"source":["!git clone https://github.com/google/seq2seq.git\n","!pip install -e seq2seq\n","!pip install git+https://github.com/huggingface/transformers"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T14:42:11.054883Z","iopub.status.busy":"2023-09-01T14:42:11.054469Z","iopub.status.idle":"2023-09-01T14:42:11.063013Z","shell.execute_reply":"2023-09-01T14:42:11.062080Z","shell.execute_reply.started":"2023-09-01T14:42:11.054846Z"},"trusted":true},"outputs":[],"source":["@dataclass\n","class ModelArguments:\n","    \"\"\"\n","    Arguments pertaining to which model/config/tokenizer we are going to fine-tune from.\n","    \"\"\"\n","\n","    model_name_or_path: str = field(\n","        metadata={\"help\": \"Path to pretrained model or model identifier from huggingface.co/models\"}\n","    )\n","    config_name: Optional[str] = field(\n","        default=None, metadata={\"help\": \"Pretrained config name or path if not the same as model_name\"}\n","    )\n","    tokenizer_name: Optional[str] = field(\n","        default=None, metadata={\"help\": \"Pretrained tokenizer name or path if not the same as model_name\"}\n","    )\n","    cache_dir: Optional[str] = field(\n","        default=None, metadata={\"help\": \"Where do you want to store the pretrained models downloaded from s3\"}\n","    )"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T14:42:11.065133Z","iopub.status.busy":"2023-09-01T14:42:11.064777Z","iopub.status.idle":"2023-09-01T14:42:11.111959Z","shell.execute_reply":"2023-09-01T14:42:11.110921Z","shell.execute_reply.started":"2023-09-01T14:42:11.065098Z"},"trusted":true},"outputs":[],"source":["from transformers import TrainingArguments"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T14:42:11.113882Z","iopub.status.busy":"2023-09-01T14:42:11.113331Z","iopub.status.idle":"2023-09-01T14:42:11.223369Z","shell.execute_reply":"2023-09-01T14:42:11.222355Z","shell.execute_reply.started":"2023-09-01T14:42:11.113848Z"},"trusted":true},"outputs":[],"source":["args = transformers.Seq2SeqTrainingArguments(\n","    'news-summ',\n","    evaluation_strategy='epoch',\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=1,\n","    per_device_eval_batch_size= 1,\n","    gradient_accumulation_steps=2,\n","    weight_decay=0.01,\n","    save_total_limit=2,\n","#     num_train_epochs=1,\n","#     eval_steps=10000,\n","    max_steps=10000,\n","    predict_with_generate=True,\n","    eval_accumulation_steps=1,\n","    fp16=True\n","    )\n","#only CUDA available -> fp16=True\n","     "]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T14:42:11.226984Z","iopub.status.busy":"2023-09-01T14:42:11.226706Z","iopub.status.idle":"2023-09-01T17:16:56.475125Z","shell.execute_reply":"2023-09-01T17:16:56.474084Z","shell.execute_reply.started":"2023-09-01T14:42:11.226959Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":["  ········································\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/html":["wandb version 0.15.9 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.15.5"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20230901_144638-f3ntmiii</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/akash2002/huggingface/runs/f3ntmiii' target=\"_blank\">whole-pond-25</a></strong> to <a href='https://wandb.ai/akash2002/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/akash2002/huggingface' target=\"_blank\">https://wandb.ai/akash2002/huggingface</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/akash2002/huggingface/runs/f3ntmiii' target=\"_blank\">https://wandb.ai/akash2002/huggingface/runs/f3ntmiii</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='10000' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [10000/10000 2:29:38, Epoch 0/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>0.000000</td>\n","      <td>0.000769</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/plain":["TrainOutput(global_step=10000, training_loss=0.1374804716573366, metrics={'train_runtime': 9278.9179, 'train_samples_per_second': 4.311, 'train_steps_per_second': 1.078, 'total_flos': 1.408890875904e+16, 'train_loss': 0.1374804716573366, 'epoch': 0.14})"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["trainer = Trainer(\n","    model=roberta_shared,\n","    args=args,\n","#     compute_metrics=compute_metrics,\n","    train_dataset=train_data,\n","    eval_dataset=val_data,\n",")\n","trainer.train()"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T17:16:56.483728Z","iopub.status.busy":"2023-09-01T17:16:56.479514Z","iopub.status.idle":"2023-09-01T17:16:57.552575Z","shell.execute_reply":"2023-09-01T17:16:57.551374Z","shell.execute_reply.started":"2023-09-01T17:16:56.483686Z"},"trusted":true},"outputs":[],"source":["trainer.save_model(\"/kaggle/working/my_fine_tuned_model\")"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T18:05:09.407571Z","iopub.status.busy":"2023-09-01T18:05:09.407148Z","iopub.status.idle":"2023-09-01T18:05:10.412410Z","shell.execute_reply":"2023-09-01T18:05:10.411308Z","shell.execute_reply.started":"2023-09-01T18:05:09.407517Z"},"trusted":true},"outputs":[],"source":["from datasets import load_dataset, load_metric"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T18:13:27.150955Z","iopub.status.busy":"2023-09-01T18:13:27.150518Z","iopub.status.idle":"2023-09-01T18:13:27.156043Z","shell.execute_reply":"2023-09-01T18:13:27.154590Z","shell.execute_reply.started":"2023-09-01T18:13:27.150923Z"},"trusted":true},"outputs":[],"source":["import pandas as pd"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T18:13:28.207931Z","iopub.status.busy":"2023-09-01T18:13:28.207012Z","iopub.status.idle":"2023-09-01T18:13:29.638952Z","shell.execute_reply":"2023-09-01T18:13:29.637887Z","shell.execute_reply.started":"2023-09-01T18:13:28.207894Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Data size: 11490\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>article</th>\n","      <th>highlights</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Ever noticed how plane seats appear to be gett...</td>\n","      <td>Experts question if  packed out planes are put...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>A drunk teenage boy had to be rescued by secur...</td>\n","      <td>Drunk teenage boy climbed into lion enclosure ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Dougie Freedman is on the verge of agreeing a ...</td>\n","      <td>Nottingham Forest are close to extending Dougi...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Liverpool target Neto is also wanted by PSG an...</td>\n","      <td>Fiorentina goalkeeper Neto has been linked wit...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Bruce Jenner will break his silence in a two-h...</td>\n","      <td>Tell-all interview with the reality TV star, 6...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>11485</th>\n","      <td>Our young Earth may have collided with a body ...</td>\n","      <td>Oxford scientists say a Mercury-like body stru...</td>\n","    </tr>\n","    <tr>\n","      <th>11486</th>\n","      <td>A man facing trial for helping his former love...</td>\n","      <td>Man accused of helping former lover kill woman...</td>\n","    </tr>\n","    <tr>\n","      <th>11487</th>\n","      <td>A dozen or more metal implements are arranged ...</td>\n","      <td>Marianne Power tried the tuning fork facial at...</td>\n","    </tr>\n","    <tr>\n","      <th>11488</th>\n","      <td>Brook Lopez dominated twin brother Robin with ...</td>\n","      <td>Brooklyn Nets beat the Portland Trail Blazers ...</td>\n","    </tr>\n","    <tr>\n","      <th>11489</th>\n","      <td>A Chinese hospital is being painstakingly move...</td>\n","      <td>Chinese hospital marked for demolition because...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>11490 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                 article  \\\n","0      Ever noticed how plane seats appear to be gett...   \n","1      A drunk teenage boy had to be rescued by secur...   \n","2      Dougie Freedman is on the verge of agreeing a ...   \n","3      Liverpool target Neto is also wanted by PSG an...   \n","4      Bruce Jenner will break his silence in a two-h...   \n","...                                                  ...   \n","11485  Our young Earth may have collided with a body ...   \n","11486  A man facing trial for helping his former love...   \n","11487  A dozen or more metal implements are arranged ...   \n","11488  Brook Lopez dominated twin brother Robin with ...   \n","11489  A Chinese hospital is being painstakingly move...   \n","\n","                                              highlights  \n","0      Experts question if  packed out planes are put...  \n","1      Drunk teenage boy climbed into lion enclosure ...  \n","2      Nottingham Forest are close to extending Dougi...  \n","3      Fiorentina goalkeeper Neto has been linked wit...  \n","4      Tell-all interview with the reality TV star, 6...  \n","...                                                  ...  \n","11485  Oxford scientists say a Mercury-like body stru...  \n","11486  Man accused of helping former lover kill woman...  \n","11487  Marianne Power tried the tuning fork facial at...  \n","11488  Brooklyn Nets beat the Portland Trail Blazers ...  \n","11489  Chinese hospital marked for demolition because...  \n","\n","[11490 rows x 2 columns]"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["df3=pd.read_csv(r\"/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/test.csv\")\n","df3.drop(columns=['id'],inplace=True)\n","df3 = df3.dropna()\n","print(\"Data size:\",len(df3))\n","df3.head()\n","df3"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T18:15:50.097496Z","iopub.status.busy":"2023-09-01T18:15:50.097102Z","iopub.status.idle":"2023-09-01T18:15:50.108479Z","shell.execute_reply":"2023-09-01T18:15:50.107361Z","shell.execute_reply.started":"2023-09-01T18:15:50.097463Z"},"trusted":true},"outputs":[],"source":["test_data=Dataset.from_pandas(df3[:114])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-09-01T18:26:26.598284Z","iopub.status.idle":"2023-09-01T18:26:26.599495Z","shell.execute_reply":"2023-09-01T18:26:26.599255Z","shell.execute_reply.started":"2023-09-01T18:26:26.599226Z"},"trusted":true},"outputs":[],"source":["pip install rouge_score"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-09-01T18:26:26.601081Z","iopub.status.idle":"2023-09-01T18:26:26.601639Z","shell.execute_reply":"2023-09-01T18:26:26.601365Z","shell.execute_reply.started":"2023-09-01T18:26:26.601340Z"},"trusted":true},"outputs":[],"source":["rouge = datasets.load_metric(\"rouge\")\n","\n","def compute_metrics(pred):\n","    labels_ids = pred.label_ids\n","    pred_ids = pred.predictions\n","\n","    # all unnecessary tokens are removed\n","    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n","    labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n","    label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n","\n","    rouge_output = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rouge2\"])[\"rouge2\"].mid\n","\n","    return {\n","        \"rouge2_precision\": round(rouge_output.precision, 4),\n","        \"rouge2_recall\": round(rouge_output.recall, 4),\n","        \"rouge2_fmeasure\": round(rouge_output.fmeasure, 4),\n","    }\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
